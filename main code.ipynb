{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":90860,"databundleVersionId":10740331,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import models\nfrom PIL import Image\nfrom torchvision.models import resnet50\nimport torch.optim as optim  # For optimization algorithms\nfrom torch.optim.lr_scheduler import CyclicLR  # For learning rate scheduling","metadata":{"id":"vdMi4cTEsHSM","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:00:32.605666Z","iopub.execute_input":"2025-01-12T21:00:32.605987Z","iopub.status.idle":"2025-01-12T21:00:32.610646Z","shell.execute_reply.started":"2025-01-12T21:00:32.605963Z","shell.execute_reply":"2025-01-12T21:00:32.609737Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Change with path to your dataset path, you may check the exact path using the files tab (folder icon in the sidebar)\ntrain_dir = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/train\"\ntest_dir = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/test\"\n\n# Data Preprocessing\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nfull_train_dataset = ImageFolder(root=train_dir, transform=transform)\n\n\n# Validate Class to Index Mapping\nprint(\"Class to Index Mapping:\",full_train_dataset.class_to_idx)","metadata":{"id":"p7zNtbM90MyD","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:00:32.616399Z","iopub.execute_input":"2025-01-12T21:00:32.616628Z","iopub.status.idle":"2025-01-12T21:00:38.308208Z","shell.execute_reply.started":"2025-01-12T21:00:32.616608Z","shell.execute_reply":"2025-01-12T21:00:38.307394Z"}},"outputs":[{"name":"stdout","text":"Class to Index Mapping: {'antelope': 0, 'bat': 1, 'beaver': 2, 'blue+whale': 3, 'bobcat': 4, 'buffalo': 5, 'chihuahua': 6, 'cow': 7, 'dalmatian': 8, 'deer': 9, 'dolphin': 10, 'elephant': 11, 'german+shepherd': 12, 'giant+panda': 13, 'giraffe': 14, 'grizzly+bear': 15, 'hamster': 16, 'hippopotamus': 17, 'humpback+whale': 18, 'killer+whale': 19, 'leopard': 20, 'lion': 21, 'mole': 22, 'mouse': 23, 'otter': 24, 'ox': 25, 'persian+cat': 26, 'pig': 27, 'polar+bear': 28, 'raccoon': 29, 'rat': 30, 'seal': 31, 'siamese+cat': 32, 'skunk': 33, 'spider+monkey': 34, 'tiger': 35, 'walrus': 36, 'weasel': 37, 'wolf': 38, 'zebra': 39}\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"# Define the size of the validation set (15% of the full training dataset)\nvalidation_split = 0.15\nvalidation_size = int(len(full_train_dataset) * validation_split)\ntraining_size = len(full_train_dataset) - validation_size\n\n# Splitting the dataset\ntraining_dataset, validation_dataset = torch.utils.data.random_split(\n    full_train_dataset,\n    [training_size, validation_size],\n    generator=torch.Generator().manual_seed(13)  # Manual Seed for reproducibility every time model is trained\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:00:38.309192Z","iopub.execute_input":"2025-01-12T21:00:38.309508Z","iopub.status.idle":"2025-01-12T21:00:38.314098Z","shell.execute_reply.started":"2025-01-12T21:00:38.309479Z","shell.execute_reply":"2025-01-12T21:00:38.313462Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# DataLoader for training data\ntrain_loader = DataLoader(\n    training_dataset,\n    batch_size=32,  \n    shuffle=True,    # Shuffles the data at every epoch\n    num_workers=4    # Kaggle processing limit is 4\n)\n\n# DataLoader for validation data\nval_loader = DataLoader(\n    validation_dataset,\n    batch_size=32,  \n    shuffle=False,  # No need to shuffle validation data\n    num_workers=4    \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:00:38.315698Z","iopub.execute_input":"2025-01-12T21:00:38.315925Z","iopub.status.idle":"2025-01-12T21:00:38.336076Z","shell.execute_reply.started":"2025-01-12T21:00:38.315906Z","shell.execute_reply":"2025-01-12T21:00:38.335069Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# Model Definition\nclass MultilabelClassifier(nn.Module):\n    def __init__(self,  num_classes):\n        super(MultilabelClassifier, self).__init__()\n        self.base_model = models.resnet50(pretrained=True)\n        self.base_model.fc = nn.Linear(self.base_model.fc.in_features,num_classes)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.base_model(x)\n        return self.sigmoid(x)\n\n\n\n\n","metadata":{"id":"jQd1JQ4_0Ssu","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:00:38.337352Z","iopub.execute_input":"2025-01-12T21:00:38.337656Z","iopub.status.idle":"2025-01-12T21:00:38.351431Z","shell.execute_reply.started":"2025-01-12T21:00:38.337627Z","shell.execute_reply":"2025-01-12T21:00:38.350513Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_classes = len(full_train_dataset.classes)\nmodel = MultilabelClassifier(num_classes).to(device)\n\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()  # Binary Cross-Entropy Loss\n\n# Define the optimizer to update the model's parameters during training\n\noptimizer = optim.AdamW(model.parameters(), weight_decay=1e-4)\n\n\nlearning_rate_scheduler = CyclicLR(\n    optimizer,\n    base_lr=3e-5,  # Lower bound of the learning rate\n    max_lr=3e-4,    # Upper bound of the learning rate\n    step_size_up = 100,  # Number of iterations to increase the learning rate\n    mode=\"triangular2\",  # Shape of the learning rate cycle\n    cycle_momentum=False  # Whether to cycle momentum\n)\n\n# Training loop\nepochs = 5\nbest_val_f1 = 0.0\n\nfor epoch in range(epochs):\n    model.train()\n    train_loss = 0.0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {train_loss/len(train_loader):.4f}\")\n\n#validation phase\nmodel.eval()\nrunning_val_loss = 0.0\nwith torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            running_val_loss += loss.item()\n\navg_train_loss = train_loss / len(train_loader)\navg_val_loss = running_val_loss / len(val_loader)\nprint(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n","metadata":{"id":"lDZk3mPe0VNg","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:00:38.352647Z","iopub.execute_input":"2025-01-12T21:00:38.352986Z","execution_failed":"2025-01-12T21:03:54.367Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 3.3722\nEpoch [2/5], Loss: 3.2780\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Prediction\nmodel.eval()\ntest_images = [f for f in os.listdir(test_dir) if f.endswith('.jpg')]\ntest_predictions = []\n\nfor img_name in test_images:\n    img_path = os.path.join(test_dir, img_name)\n    image = Image.open(img_path).convert('RGB')\n    image = transform(image).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        outputs = model(image)\n        predicted_class = torch.argmax(outputs, dim=1).item()\n        test_predictions.append((img_name, full_train_dataset.classes[predicted_class]))\n\n# Save Predictions\nsubmission = pd.DataFrame(test_predictions, columns=['image_id', 'class'])\nsubmission.to_csv(\"/kaggle/working/predictions.csv\", index=False)","metadata":{"id":"pLSg4S3F0Wl2","trusted":true,"execution":{"execution_failed":"2025-01-12T21:03:54.367Z"}},"outputs":[],"execution_count":null}]}